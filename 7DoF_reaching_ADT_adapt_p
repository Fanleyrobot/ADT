#!/bin/bash

# File
# @description:
#     This file is for adapting a preception module
# 	  using the adversarial discriminative sim-to-real transfer.
# @version: V0.22
# @author: Fangyi Zhang   email:gzzhangfangyi@gmail.com
# @acknowledgement:
#     ARC Centre of Excellence for Robotic Vision (ACRV)
#     Queensland Univsersity of Technology (QUT)
# @history:
#     V0.00   15/04/2018  developed the first version
#     V0.10   22/05/2019  cleaned up this bash file
#	  V0.20	  31/05/2019  re-organized the parameter settings
#	  V0.22	  11/06/2019  added PID_map_scalar to set the strength of the adversarial cmd

if [ -z "$1" ]
  then echo "Please provide the filename of the ploted curve and history data, e.g.  ./manipulation_cpu threelink "; exit 0
fi

PLOTNAME=$1

display=1 # Set to 1 to watch agent train (works only if display is available)
# Check GUI availability
xhost +si:localuser:$( whoami ) >&/dev/null && {
	# GUI available
	display_avail=1
} || {
	# GUI not available
	display_avail=0
}

#======= Simulator Settings & Input Dimension ===================
sim_file="simulator/vrep_baxter_picking_inhand_cam_dataset_adt_adapt_p"
ncols=3 # the number of color chanels of the inputs to networks, it is 1 here since images will be rescaled and transfered to grey image before being input to networks.
feature_dim={256,256} # the dimention of one frame of output features from the simulator after scaling
state_dim=65536 # the one-dimensional size of one input frame

#======= Network Settings ==================
agent="ADTLearner"
netfile="\"net/convnet_percept_GNet\""
# preproc_net="\"net/net_downsample_256_complex\""
# p_preproc_net="\"net/net_downsample_256_full_y\""
# preproc_net="\"net/net_downsample_256_complex_with_normalization\""
preproc_net="\"net/net_downsample_256_with_normalization\""
# auto_preproc_net="\"net/net_downsample_48_with_normalization\""
# auto_preproc_net="\"net/net_downsample_48\""
# preproc_net="\"net/net_downsample_129_full_y\""
agent_type="CNN"
agent_name=$agent_type"_"$PLOTNAME
hist_len=1 # the number of frames input to the network
fixed_layers={} # set the index of the weight-fixed layers
agent_mode=2 # set agent mode three mode options: 1:e2e, 2:perception, 3:ctrl; it is e2e by default
# network="e2e_PP52000_CC6000000.t7" # pre-trained model
# network="e2e_PP48_28000_CC6000000.t7" # pre-trained model
network="CNN_net_adda_pre.t7" # pre-trained model
# network="e2e_sim_CC6000000.t7" # pre-trained model

#======= Training Settings ==================
steps=50000000 # the maximum training steps
n_replay=1 #Minibach learning how many times in each training step
wc=0 #the lamda of L2 regularization term
seed=1 #random seed
lr=0.001 # learning rate at the beginning
lr_end=0.001 # leaqrning rate at the end
lr_startt=5000 # the step of teh learning rate start point 
lr_endt=100000 # the step of the learning rate end point
clip_delta=1 # delta clip, where deltas = predictions - labels
minibatch_size=4 # the minibatch size
n_vali_set=4 # the size of the validation set

semi_supervised=true # whether to enable the semi-supervised mode to make use of the labelled real data
adversarial_mode=2 # what adversarial loss to use, 1:ADDA, 2:DC. More losses can be added under the framework if necessary
shortcut_mode=false # whether to enable the shorcut mode where a network with shortcuts are used
parallel_mode=false # whether to update the source encoder in the mean time
d_lr_discount=1 # the learning rate discount ratio particularly for the adversarial transfer loss (including the updates of both discriminator and encoder)

use_PID=true # whether use the PID controller in the ADTLearner
Kp=0.4 # the proportion scalar of the PID controller	
Ki=0.008 # the integral scalar of the PID controller
Kd=0.0 # the derivative scalar of the PID controller
desired_d_loss=0.28 # the desired discriminative loss for the PID controller
PID_map_scalar=0.02 # the scalar weight to control the mapping from u to gama, i.e., strength of the adversarial cmd

d_loss_filter_length=1 # number of samples for filttering the real-time discriminator loss
encoder_start=0 # the step to start training the encoder, not used in current method
d_episode_steps=1 # every d_episode_steps steps to start an encoder training phase
e_episode_steps=1 # e_episode_steps training steps will be used in the encoder training phase

agent_params="parallel_mode="$parallel_mode",Kp="$Kp",Ki="$Ki",Kd="$Kd",PID_map_scalar="$PID_map_scalar",desired_d_loss="$desired_d_loss",mode="$agent_mode",adversarial_mode="$adversarial_mode",semi_supervised="$semi_supervised",shortcut_mode="$shortcut_mode",fixed_layers="$fixed_layers",lr="$lr",lr_end="$lr_end",lr_endt="$lr_endt",d_lr_discount="$d_lr_discount",hist_len="$hist_len",lr_startt="$lr_startt",n_replay="$n_replay",network="$netfile",preproc="$preproc_net",feature_dim="$feature_dim",state_dim="$state_dim",minibatch_size="$minibatch_size",ncols="$ncols",wc="$wc",clip_delta="$clip_delta",n_vali_set="$n_vali_set",encoder_start="$encoder_start",d_episode_steps="$d_episode_steps",e_episode_steps="$e_episode_steps",use_PID="$use_PID",d_loss_filter_length="$d_loss_filter_length""

#======= Evaluation Settings ====================
eval_freq=1000
prog_freq=1000
save_freq=1000
# Added by Fangyi Zhang to set different plot filename
plot_filename=$PLOTNAME
# End Add

#======= Hardware Settings ======================
gpu=-1 # if use CPU, set it to -1, otherwise, the program will use gpu
num_threads=4 # the number of threads,
# the torch will autonomously take use of multiple cpus to speed up the performance.
# normally, one cpu takes charge of two threads

args="-network $network -name $agent_name -agent $agent -agent_params $agent_params -steps $steps -eval_freq $eval_freq -prog_freq $prog_freq -save_freq $save_freq -gpu $gpu -seed $seed -threads $num_threads -display $display -display_avail $display_avail -plot_filename $plot_filename -sim_file $sim_file"
# args="-network $network -name $agent_name -agent $agent -agent_params $agent_params -steps $steps -eval_freq $eval_freq -eval_steps $eval_steps -prog_freq $prog_freq -save_freq $save_freq -gpu $gpu -seed $seed -threads $num_threads -display $display -display_avail $display_avail -plot_filename $plot_filename -sim_file $sim_file -feature_mode $feature_mode"
echo $args

cd deep_manipulation
torch_path=$TORCH_PATH # TORCH_PATH is a system variable generated after installing the torch dependencies by running "install_dependencies.sh"
qlua="$torch_path/bin/qlua" # qlua normal place
luajit="$torch_path/bin/luajit" #luajit normal place
script="main_scripts/adapt_p_adt.lua"
if [[ "$display_avail" == 1 ]]; then
	# GUI is available
	if [ -e "$qlua" ]
	then $qlua $script $args
	else
	echo "cannot find $qlua"
	fi
else
	# GUI is not available
	if [ -e "$luajit" ]
	then $luajit $script $args
	else
	echo "cannot find $luajit"
	fi
fi
